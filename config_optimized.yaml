# config_optimized.yaml
device: "cuda"

training:
  batch_size: 256 # 你可以根据显存情况尝试 256
  epochs: 200 # 训练轮数
  learning_rate: 0.001 # 初始学习率
  weight_decay: 0.05 # 权重衰减

data:
  root: "cifar-10-batches-py"
  num_workers: 8 # 根据你的 CPU 核心数调整
  download: true

model:
  num_classes: 10
  dropout_rate: 0.0 # 残差块内部 dropout (可选，通常较小)
  classifier_dropout: 0.2 # 分类器 dropout

data_augmentation:
  random_crop_padding: 4
  random_hflip_prob: 0.5
  cutout_n_holes: 1 # Cutout 参数 (如果使用自定义 Cutout)
  cutout_length: 12  # Cutout 参数 (如果使用自定义 Cutout)
  # random_erase_prob: 0.1 # RandomErasing 参数 (在代码中直接设置)

normalization:
  mean: [0.4914, 0.4822, 0.4465]
  std: [0.2023, 0.1994, 0.2010]

saving:
  model_path: "cifar10_resnet_optimized_best.pth"
  plot_path: "cifar10_resnet_optimized_training_curve.png"